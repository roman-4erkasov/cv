{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0d01481-1c7b-44fc-b998-6fdcebf5ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from torch import optim\n",
    "from torch.nn.functional import ctc_loss, log_softmax\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from contest.common import get_logger\n",
    "from contest.recognition.dataset import RecognitionDataset\n",
    "from contest.recognition.model import get_model\n",
    "from contest.recognition.transforms import get_train_transforms\n",
    "from contest.recognition.utils import abc\n",
    "\n",
    "PATH_DATA = \"/home/ubuntu/datasets/segment_car_plate/data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92e7c739-7252-400e-9953-ef816580ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import Compose, Resize, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e551922-475a-48c8-a355-bb6c438d4287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malways_apply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Resize the input to the given height and width.\n",
       "\n",
       "Args:\n",
       "    height (int): desired height of the output.\n",
       "    width (int): desired width of the output.\n",
       "    interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:\n",
       "        cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.\n",
       "        Default: cv2.INTER_LINEAR.\n",
       "    p (float): probability of applying the transform. Default: 1.\n",
       "\n",
       "Targets:\n",
       "    image, mask, bboxes, keypoints\n",
       "\n",
       "Image types:\n",
       "    uint8, float32\n",
       "\u001b[0;31mFile:\u001b[0m           ~/venv/lib/python3.8/site-packages/albumentations/augmentations/geometric/resize.py\n",
       "\u001b[0;31mType:\u001b[0m           SerializableMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Resize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0705efed-57d0-4bd0-bf86-2deed5c1bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_w, image_h = 320, 64\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8c88ac9-9d8e-48c4-bc64-e5395ee4eb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_transforms = get_train_transforms((image_w, image_h))\n",
    "train_dataset = RecognitionDataset(PATH_DATA, os.path.join(PATH_DATA, \"train_recognition.json\"),\n",
    "                                   abc=abc, transforms=train_transforms, split=\"train\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8,\n",
    "                                  collate_fn=train_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22fea1dd-f621-473b-8af6-1e677a83a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa18cc73-c3d1-4176-a922-6836f11e51df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 64, 320])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"images\"].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7ac9067-6cea-40d0-8f30-053fdef44ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ebae722-50c4-4a40-a022-32ddc5450e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
       "the given dataset.\n",
       "\n",
       "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
       "iterable-style datasets with single- or multi-process loading, customizing\n",
       "loading order and optional automatic batching (collation) and memory pinning.\n",
       "\n",
       "See :py:mod:`torch.utils.data` documentation page for more details.\n",
       "\n",
       "Args:\n",
       "    dataset (Dataset): dataset from which to load the data.\n",
       "    batch_size (int, optional): how many samples per batch to load\n",
       "        (default: ``1``).\n",
       "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
       "        at every epoch (default: ``False``).\n",
       "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
       "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
       "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
       "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
       "        returns a batch of indices at a time. Mutually exclusive with\n",
       "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
       "        and :attr:`drop_last`.\n",
       "    num_workers (int, optional): how many subprocesses to use for data\n",
       "        loading. ``0`` means that the data will be loaded in the main process.\n",
       "        (default: ``0``)\n",
       "    collate_fn (callable, optional): merges a list of samples to form a\n",
       "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
       "        map-style dataset.\n",
       "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
       "        into device/CUDA pinned memory before returning them.  If your data elements\n",
       "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
       "        see the example below.\n",
       "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
       "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
       "        the size of dataset is not divisible by the batch size, then the last batch\n",
       "        will be smaller. (default: ``False``)\n",
       "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
       "        from workers. Should always be non-negative. (default: ``0``)\n",
       "    worker_init_fn (callable, optional): If not ``None``, this will be called on each\n",
       "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
       "        input, after seeding and before data loading. (default: ``None``)\n",
       "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
       "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
       "        `base_seed` for workers. (default: ``None``)\n",
       "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
       "        in advance by each worker. ``2`` means there will be a total of\n",
       "        2 * num_workers batches prefetched across all workers. (default: ``2``)\n",
       "    persistent_workers (bool, optional): If ``True``, the data loader will not shutdown\n",
       "        the worker processes after a dataset has been consumed once. This allows to\n",
       "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
       "    pin_memory_device (str, optional): the data loader will copy Tensors\n",
       "        into device pinned memory before returning them if pin_memory is set to true.\n",
       "\n",
       "\n",
       ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
       "             cannot be an unpicklable object, e.g., a lambda function. See\n",
       "             :ref:`multiprocessing-best-practices` on more details related\n",
       "             to multiprocessing in PyTorch.\n",
       "\n",
       ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
       "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
       "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
       "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
       "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
       "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
       "             loading to avoid duplicate data.\n",
       "\n",
       "             However, if sharding results in multiple workers having incomplete last batches,\n",
       "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
       "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
       "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
       "             cases in general.\n",
       "\n",
       "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
       "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
       "             `Multi-process data loading`_.\n",
       "\n",
       ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
       "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265172b6-d39a-48e8-95cb-6eee63455fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
